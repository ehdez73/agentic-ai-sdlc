{
  "name": "Agentic SDLC (MCP)",
  "nodes": [
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        -360,
        -80
      ],
      "id": "a38881e7-b16a-4b8b-8ccc-ee6c11b2b3c7",
      "name": "When chat message received",
      "webhookId": "5afdf756-32c3-4e03-badc-39d192e8eb05"
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "You are a highly analytical assistant trained to support Agile software teams by interpreting conversations from \"3 Amigos\" meetings, where a product owner, developer, and QA tester discuss user stories.\n\nYour task is to process the meeting transcript and sequentially invoke specialized tools to perform the following actions:\n\n1 - Extract all clear, testable functional requirements discussed or implied in the conversation.\n2 - Generate Gherkin scenarios that align directly with the extracted functional requirements.\n3 - Produce structured documentation that combines the requirements and Gherkin scenarios in a clear, organized format.\n4 - Respond to the user with a summary containing the functional requirements and the corresponding Gherkin scenarios.\n\nSpecial considerations:\n\n* If any part of the conversation includes ambiguity, clarify assumptions conservatively.\n* Edge cases and validation rules raised by testers should be reflected in the output.\n* Constraints and implementation notes from developers should be captured as part of the requirements when relevant.\n* Highlight any explicit business rules or logic discussed.\n\nOnly the final step produces a user-facing response. All intermediate steps are handled by the corresponding tools in the pipeline."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2,
      "position": [
        0,
        -80
      ],
      "id": "c5297d26-ca4f-4f95-9792-6a6b3f7994dc",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -340,
        200
      ],
      "id": "c1dd5930-5658-4b5b-847c-930534207d80",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "UlRmosQmzkwVRm3a",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "contextWindowLength": 200
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        -180,
        200
      ],
      "id": "e04e43e9-db62-4c36-96ef-079c4813010f",
      "name": "Simple Memory"
    },
    {
      "parameters": {
        "description": "Call this tool to extract functional requirements from the conversation",
        "workflowId": {
          "__rl": true,
          "value": "4wSumomhUiLKYUbg",
          "mode": "list",
          "cachedResultName": "Feature Extractor"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "request": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('request', ``, 'string') }}"
          },
          "matchingColumns": [
            "request"
          ],
          "schema": [
            {
              "id": "request",
              "displayName": "request",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2.2,
      "position": [
        580,
        160
      ],
      "id": "87e9f5b9-d140-446e-bdef-ecd3be22b8df",
      "name": "Feature Extractor"
    },
    {
      "parameters": {
        "description": "Use this tool to generate Gherkin from functional requirements",
        "workflowId": {
          "__rl": true,
          "value": "VFmvmhU45d9Ez128",
          "mode": "list",
          "cachedResultName": "Gherkin Generator"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "request": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('request', ``, 'string') }}"
          },
          "matchingColumns": [
            "request"
          ],
          "schema": [
            {
              "id": "request",
              "displayName": "request",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2.2,
      "position": [
        780,
        160
      ],
      "id": "23366a45-0b02-4756-ac72-30bcdaf24641",
      "name": "Gherkin Generator"
    },
    {
      "parameters": {
        "description": "Call this tool to generate HTML format based documentation using the functional requirements and the gherkin definitions",
        "workflowId": {
          "__rl": true,
          "value": "iu0pktHvlnotsTzS",
          "mode": "list",
          "cachedResultName": "HTML Generator"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "request": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('request', ``, 'string') }}"
          },
          "matchingColumns": [
            "request"
          ],
          "schema": [
            {
              "id": "request",
              "displayName": "request",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2.2,
      "position": [
        180,
        180
      ],
      "id": "3add2869-283e-4763-9775-ac6ae4aefacf",
      "name": "HTML Documentation"
    },
    {
      "parameters": {
        "description": "Call this tool to send emails",
        "workflowId": {
          "__rl": true,
          "value": "43pFtFYCWOM8TRQr",
          "mode": "list",
          "cachedResultName": "Mail Sender"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "request": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('request', ``, 'string') }}"
          },
          "matchingColumns": [
            "request"
          ],
          "schema": [
            {
              "id": "request",
              "displayName": "request",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2.2,
      "position": [
        320,
        200
      ],
      "id": "9f725042-2826-42f7-802d-98df3030e4af",
      "name": "Mail Sender"
    },
    {
      "parameters": {
        "sseEndpoint": "http://MacBook-Pro-de-Ernesto.local:5678/mcp/feature-extractor/sse"
      },
      "type": "@n8n/n8n-nodes-langchain.mcpClientTool",
      "typeVersion": 1,
      "position": [
        40,
        200
      ],
      "id": "354e85dc-1db5-4b52-8b67-eb65bff1bc01",
      "name": "MCP Client"
    },
    {
      "parameters": {
        "path": "feature-extractor"
      },
      "type": "@n8n/n8n-nodes-langchain.mcpTrigger",
      "typeVersion": 1,
      "position": [
        580,
        -100
      ],
      "id": "b53039c1-2102-432d-b1d1-127b7c0d3abd",
      "name": "MCP Server Trigger",
      "webhookId": "c32ca776-1ee5-44c6-a3f9-14afff053fe4"
    },
    {
      "parameters": {
        "content": "",
        "height": 480,
        "width": 880
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -440,
        -140
      ],
      "typeVersion": 1,
      "id": "b67c3fc0-341f-45d6-9638-935fab019f30",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "content": "",
        "height": 480,
        "width": 480,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        480,
        -140
      ],
      "typeVersion": 1,
      "id": "aea2a0ee-80d9-4384-8eda-7572ef108cb2",
      "name": "Sticky Note1"
    }
  ],
  "pinData": {},
  "connections": {
    "When chat message received": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Feature Extractor": {
      "ai_tool": [
        [
          {
            "node": "MCP Server Trigger",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Gherkin Generator": {
      "ai_tool": [
        [
          {
            "node": "MCP Server Trigger",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "HTML Documentation": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Mail Sender": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "MCP Client": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "3831b9c9-2406-4875-874c-790ebbdd0ea4",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "e8e13ca28292496bb6e988e5705c642203affe74cda520b04aa7144af8b1cf34"
  },
  "id": "8IidlJbGz6jfWPl2",
  "tags": []
}